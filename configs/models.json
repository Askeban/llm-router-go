[
  {
    "id": "anthropic-claude-3-opus",
    "provider": "anthropic",
    "display_name": "Claude 3 Opus",
    "context_window": 200000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.075,
    "avg_latency_ms": 2800,
    "open_source": false,
    "capabilities": {
      "coding": 0.8490000000000001,
      "math": 0.95,
      "reasoning": 0.86,
      "support": 0.7,
      "writing": 0.7
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "math"
    ],
    "notes": "Enhanced with benchmark data from trun_data_2024.json",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-3-sonnet",
    "provider": "anthropic",
    "display_name": "Claude 3 Sonnet",
    "context_window": 200000,
    "cost_in_per_1k": 0.003,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 2200,
    "open_source": false,
    "capabilities": {
      "coding": 0.73,
      "math": 0.88,
      "reasoning": 0.8493999999999999,
      "support": 0.7,
      "writing": 0.7
    },
    "best_at": null,
    "tags": [
      "closed",
      "math"
    ],
    "notes": "Enhanced with benchmark data from trun_data_2024.json",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-3.5-sonnet",
    "provider": "anthropic",
    "display_name": "Claude 3.5 Sonnet",
    "context_window": 200000,
    "cost_in_per_1k": 0.003,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 2200,
    "open_source": false,
    "capabilities": {
      "coding": 0.64,
      "math": 0.88,
      "reasoning": 0.73,
      "support": 0.8,
      "writing": 0.8
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "coding"
    ],
    "notes": "Excellent reasoning",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-4-sonnet-thinking",
    "provider": "anthropic",
    "display_name": "Claude 4 Sonnet Thinking",
    "context_window": 1000000,
    "cost_in_per_1k": 0.003,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.7358,
      "math": 0.8525,
      "reasoning": 0.9525,
      "support": 0.8043,
      "writing": 0.7019
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "coding"
    ],
    "notes": "Global Average Score: 72.08. Context and cost data for Claude Sonnet 4.. Other scores -\u003e Agentic Coding: 30.00, Data Analysis: 69.84.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "google-gemini-1.5-pro",
    "provider": "google",
    "display_name": "Google Gemini 1.5 Pro",
    "context_window": 1000000,
    "cost_in_per_1k": 0.0025,
    "cost_out_per_1k": 0.0075,
    "avg_latency_ms": 1800,
    "open_source": false,
    "capabilities": {
      "coding": 0.6,
      "math": 0.86,
      "reasoning": 0.86,
      "support": 0.88,
      "writing": 0.88
    },
    "best_at": null,
    "tags": [
      "closed",
      "multimodal"
    ],
    "notes": "Strong multimodal",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-4",
    "provider": "openai",
    "display_name": "OpenAI GPT-4",
    "context_window": 128000,
    "cost_in_per_1k": 0.03,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 2500,
    "open_source": false,
    "capabilities": {
      "coding": 0.67,
      "math": 0.92,
      "reasoning": 0.8489999999999999,
      "support": 0.7,
      "writing": 0.7
    },
    "best_at": null,
    "tags": [
      "closed",
      "math",
      "general"
    ],
    "notes": "Enhanced with benchmark data from trun_data_2024.json",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-4o",
    "provider": "openai",
    "display_name": "OpenAI GPT-4o",
    "context_window": 128000,
    "cost_in_per_1k": 0.005,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 2500,
    "open_source": false,
    "capabilities": {
      "coding": 0.72,
      "math": 0.9,
      "reasoning": 0.82,
      "support": 0.9,
      "writing": 0.9
    },
    "best_at": null,
    "tags": [
      "closed",
      "general",
      "vision"
    ],
    "notes": "High performance general model",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openrouter-deepseek-coder-v2",
    "provider": "openrouter",
    "display_name": "DeepSeek Coder V2 (hosted)",
    "context_window": 128000,
    "cost_in_per_1k": 0.0006,
    "cost_out_per_1k": 0.0015,
    "avg_latency_ms": 2000,
    "open_source": false,
    "capabilities": {
      "coding": 0.86,
      "math": 0.75,
      "reasoning": 0.78,
      "support": 0.72,
      "writing": 0.7
    },
    "best_at": null,
    "tags": [
      "coding",
      "cheap"
    ],
    "notes": "Strong for code",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "deepseek-deepseek-v3-1-thinking",
    "provider": "openrouter",
    "display_name": "DeepSeek V3.1 Thinking",
    "context_window": 128000,
    "cost_in_per_1k": 0,
    "cost_out_per_1k": 0,
    "avg_latency_ms": 0,
    "open_source": true,
    "capabilities": {
      "coding": 0.7031,
      "math": 0.8872,
      "reasoning": 0.9067,
      "support": 0.8585,
      "writing": 0.704
    },
    "best_at": null,
    "tags": [
      "open",
      "reasoning",
      "math",
      "coding"
    ],
    "notes": "Global Average Score: 70.75. Context data for base DeepSeek V3 model.. Other scores -\u003e Agentic Coding: 25.00, Data Analysis: 64.33.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openrouter-meta-llama-3-70b-instruct",
    "provider": "openrouter",
    "display_name": "Llama 3 70B Instruct (hosted)",
    "context_window": 8000,
    "cost_in_per_1k": 0.0008,
    "cost_out_per_1k": 0.0016,
    "avg_latency_ms": 2200,
    "open_source": true,
    "capabilities": {
      "coding": 0.72,
      "math": 0.74,
      "reasoning": 0.78,
      "support": 0.8,
      "writing": 0.82
    },
    "best_at": null,
    "tags": [
      "open",
      "general"
    ],
    "notes": "Open-weight value",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5",
    "provider": "openai",
    "display_name": "GPT-5",
    "context_window": 400000,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.749,
      "math": 1,
      "reasoning": 0.894,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "math",
      "agentic"
    ],
    "notes": "Benchmark Highlights: GPQA Diamond: 89.4%, AIME 2025: 100%, SWE Bench: 74.9%. Premier choice for complex coding and agentic tasks.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5-high",
    "provider": "openai",
    "display_name": "GPT-5 High",
    "context_window": 400000,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.7531,
      "math": 0.9277,
      "reasoning": 0.9817,
      "support": 0.8811,
      "writing": 0.8083
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "coding"
    ],
    "notes": "Global Average Score: 78.59. Context and cost data for base GPT-5 model.. Other scores -\u003e Agentic Coding: 43.33, Data Analysis: 71.63.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5-medium",
    "provider": "openai",
    "display_name": "GPT-5 Medium",
    "context_window": 400000,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.7325,
      "math": 0.8995,
      "reasoning": 0.9658,
      "support": 0.8899,
      "writing": 0.7899
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math"
    ],
    "notes": "Global Average Score: 76.45. Context and cost data for base GPT-5 model.. Other scores -\u003e Agentic Coding: 35.00, Data Analysis: 72.38.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5-low",
    "provider": "openai",
    "display_name": "GPT-5 Low",
    "context_window": 400000,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.7249,
      "math": 0.8533,
      "reasoning": 0.9047,
      "support": 0.8899,
      "writing": 0.7873
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math"
    ],
    "notes": "Global Average Score: 75.34. Context and cost data for base GPT-5 model.. Other scores -\u003e Agentic Coding: 41.67, Data Analysis: 69.72.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5-mini",
    "provider": "openai",
    "display_name": "GPT-5 mini",
    "context_window": 400000,
    "cost_in_per_1k": 0.00025,
    "cost_out_per_1k": 0.002,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0,
      "math": 0.911,
      "reasoning": 0.823,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "balanced",
      "general"
    ],
    "notes": "Benchmark Highlights: GPQA diamond: 82.3%, AIME '25: 91.1%. A faster, cost-efficient version of GPT-5 for well-defined tasks.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-5-nano",
    "provider": "openai",
    "display_name": "GPT-5 nano",
    "context_window": 400000,
    "cost_in_per_1k": 0.00005,
    "cost_out_per_1k": 0.0004,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0,
      "math": 0.852,
      "reasoning": 0.712,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "fast",
      "cheap"
    ],
    "notes": "Benchmark Highlights: GPQA diamond: 71.2%, AIME '25: 85.2%. Fastest and most cost-effective GPT-5 version for high-throughput tasks.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-4-1",
    "provider": "openai",
    "display_name": "GPT-4.1",
    "context_window": 1000000,
    "cost_in_per_1k": 0.002,
    "cost_out_per_1k": 0.008,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.686,
      "math": 0.481,
      "reasoning": 0.902,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "long-context",
      "vision",
      "enterprise"
    ],
    "notes": "Benchmark Highlights: MMLU: 90.2%, GPQA Diamond: 66.3%, SWE-bench Verified: 54.6%, AIME '24: 48.1%. Excels in coding and understanding long contexts.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-4",
    "provider": "openai",
    "display_name": "OpenAI GPT-4",
    "context_window": 128000,
    "cost_in_per_1k": 0.03,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.67,
      "math": 0.92,
      "reasoning": 0.864,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "math",
      "general"
    ],
    "notes": "Benchmark data from Jan 2024. MMLU: 86.4, GSM8K: 92.0, HumanEval: 67.0.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-4-1-opus-thinking",
    "provider": "anthropic",
    "display_name": "Claude 4.1 Opus Thinking",
    "context_window": 200000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.075,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.7396,
      "math": 0.9116,
      "reasoning": 0.9319,
      "support": 0.8038,
      "writing": 0.7121
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "coding"
    ],
    "notes": "Global Average Score: 73.48. Context and cost data for Claude Opus 4.1.. Other scores -\u003e Agentic Coding: 33.33, Data Analysis: 71.14.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-opus-4-1",
    "provider": "anthropic",
    "display_name": "Claude Opus 4.1",
    "context_window": 200000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.075,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.745,
      "math": 0,
      "reasoning": 0.878,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "agentic",
      "research"
    ],
    "notes": "Benchmark Highlights: SWE-bench Verified: 74.5% (industry-leading), MMLU Pro (Nonthinking): 87.8%. Most intelligent model for demanding applications.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-opus-3",
    "provider": "anthropic",
    "display_name": "Claude 3 Opus",
    "context_window": 200000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.075,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.849,
      "math": 0.95,
      "reasoning": 0.868,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "finance"
    ],
    "notes": "Benchmark data from Mar 2024. MMLU: 86.8%, GSM8K: 95.0%, HumanEval: 84.9%. Ideal for complex analysis, high-level math, and strategy.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "anthropic-claude-sonnet-4",
    "provider": "anthropic",
    "display_name": "Claude Sonnet 4",
    "context_window": 200000,
    "cost_in_per_1k": 0.003,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.727,
      "math": 0.705,
      "reasoning": 0.7,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "balanced",
      "coding",
      "enterprise"
    ],
    "notes": "Benchmark Highlights: SWE-bench: 72.7%, GPQA Diamond: 70.0%, AIME: 70.5%. Optimal mix of capability, speed, and practicality.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "google-gemini-2-5-pro",
    "provider": "google",
    "display_name": "Gemini 2.5 Pro",
    "context_window": 1048576,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.638,
      "math": 0,
      "reasoning": 0.864,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "multimodal",
      "long-context",
      "reasoning"
    ],
    "notes": "Benchmark Highlights: GPQA Diamond: 86.4%, SWE-Bench Verified: 63.8%. Google's most advanced model for complex tasks.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "google-gemini-2-5-pro-max-thinking",
    "provider": "google",
    "display_name": "Gemini 2.5 Pro (Max Thinking)",
    "context_window": 1048576,
    "cost_in_per_1k": 0.00125,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.739,
      "math": 0.8419,
      "reasoning": 0.9428,
      "support": 0.7735,
      "writing": 0.7544
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "coding"
    ],
    "notes": "Global Average Score: 70.95. Context and cost data for Gemini 2.5 Pro.. Other scores -\u003e Agentic Coding: 20.00, Data Analysis: 71.50.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "meta-llama-4-scout",
    "provider": "meta",
    "display_name": "Llama 4 Scout",
    "context_window": 10000000,
    "cost_in_per_1k": 0.00011,
    "cost_out_per_1k": 0.00034,
    "avg_latency_ms": 0,
    "open_source": true,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "open",
      "long-context",
      "multimodal",
      "fast"
    ],
    "notes": "Open-weight MoE model with a 10M token context window. Natively multimodal (text and image). Ideal for memory-intensive tasks.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "meta-llama-3-1-405b",
    "provider": "meta",
    "display_name": "Llama 3.1 405B",
    "context_window": 128000,
    "cost_in_per_1k": 0.0035,
    "cost_out_per_1k": 0.0035,
    "avg_latency_ms": 0,
    "open_source": true,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "open",
      "tool-use",
      "agentic"
    ],
    "notes": "Benchmark Highlight: Top performer on BFCL (Tool Use benchmark) with 81.1%. Well-suited for building sophisticated agents.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "mistral-large-2402",
    "provider": "mistral-ai",
    "display_name": "Mistral Large (Feb 2024)",
    "context_window": 32000,
    "cost_in_per_1k": 0,
    "cost_out_per_1k": 0,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.451,
      "math": 0.812,
      "reasoning": 0.812,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "multilingual",
      "coding"
    ],
    "notes": "Benchmark data from Feb 2024. MMLU: 81.2%, GSM8K: 81.2%, HumanEval: 45.1%. Top-tier reasoning capabilities for enterprise use.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "mistral-7b",
    "provider": "mistral-ai",
    "display_name": "Mistral 7B",
    "context_window": 128000,
    "cost_in_per_1k": 0.00025,
    "cost_out_per_1k": 0.00025,
    "avg_latency_ms": 0,
    "open_source": true,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "open",
      "efficient",
      "cheap"
    ],
    "notes": "Open-source model under Apache 2.0 license. Highly efficient, outperforming much larger models on benchmarks. Uses GQA and SWA for efficiency.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "xai-grok-4",
    "provider": "xai",
    "display_name": "Grok 4",
    "context_window": 256000,
    "cost_in_per_1k": 0.003,
    "cost_out_per_1k": 0.015,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0.75,
      "math": 0.888,
      "reasoning": 0.875,
      "support": 0.7812,
      "writing": 0.7583
    },
    "best_at": null,
    "tags": [
      "closed",
      "agentic",
      "coding",
      "reasoning",
      "math"
    ],
    "notes": "Benchmark Highlights: SWE Bench: 75%, GPQA Diamond: 87.5%. Supports text and vision with real-time search. Ideal for agentic coding.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "amazon-nova-pro",
    "provider": "amazon",
    "display_name": "Amazon Nova Pro",
    "context_window": 300000,
    "cost_in_per_1k": 0.0025,
    "cost_out_per_1k": 0.0125,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0,
      "math": 0.766,
      "reasoning": 0.859,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "multimodal",
      "enterprise",
      "finance"
    ],
    "notes": "Amazon's most advanced model. Benchmarks: MMLU (85.9%), MATH (76.6%). Ideal for software engineering, financial analysis, and RAG.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "alibaba-qwen3-235b",
    "provider": "alibaba",
    "display_name": "Qwen3-235B-A22B",
    "context_window": 0,
    "cost_in_per_1k": 0,
    "cost_out_per_1k": 0,
    "avg_latency_ms": 0,
    "open_source": true,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "open",
      "coding",
      "math",
      "agentic"
    ],
    "notes": "Flagship model from Alibaba, available on Hugging Face under Apache 2.0. Achieves competitive results in coding, math, and agentic use.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "cohere-command-r-plus-08-2024",
    "provider": "cohere",
    "display_name": "Command R+ (08-2024)",
    "context_window": 128000,
    "cost_in_per_1k": 0.0025,
    "cost_out_per_1k": 0.01,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "enterprise",
      "safety"
    ],
    "notes": "A text-only model designed for enterprise applications where safety and reliability are critical.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "ibm-granite-code",
    "provider": "ibm",
    "display_name": "IBM Granite Code Models",
    "context_window": 0,
    "cost_in_per_1k": 0,
    "cost_out_per_1k": 0,
    "avg_latency_ms": 0,
    "open_source": false,
    "capabilities": {
      "coding": 0,
      "math": 0,
      "reasoning": 0,
      "support": 0,
      "writing": 0
    },
    "best_at": null,
    "tags": [
      "closed",
      "specialized",
      "coding"
    ],
    "notes": "A family of decoder-only models specifically designed for code generative tasks, trained on code from 116 programming languages.",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": null,
      "last_consolidated": "",
      "data_quality": 0
    }
  },
  {
    "id": "openai-gpt-4-5-turbo",
    "provider": "openai",
    "display_name": "GPT-4.5-Turbo",
    "context_window": 256000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.045,
    "avg_latency_ms": 1500,
    "open_source": false,
    "capabilities": {
      "coding": 0.9,
      "math": 0.74,
      "reasoning": 0.91,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - openai flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.90)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.9
    }
  },
  {
    "id": "openai-gpt-4o-mini",
    "provider": "openai",
    "display_name": "GPT-4o-Mini",
    "context_window": 384000,
    "cost_in_per_1k": 0.02,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 1800,
    "open_source": false,
    "capabilities": {
      "coding": 0.95,
      "math": 0.7799999999999999,
      "reasoning": 0.9400000000000001,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - openai flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.95)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.95
    }
  },
  {
    "id": "anthropic-claude-4-opus",
    "provider": "anthropic",
    "display_name": "Claude-4-Opus",
    "context_window": 128000,
    "cost_in_per_1k": 0.03,
    "cost_out_per_1k": 0.09,
    "avg_latency_ms": 1200,
    "open_source": false,
    "capabilities": {
      "coding": 0.75,
      "math": 0.7,
      "reasoning": 0.92,
      "support": 0.8,
      "writing": 0.95
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - anthropic flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.85)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.85
    }
  },
  {
    "id": "anthropic-claude-3-6-sonnet",
    "provider": "anthropic",
    "display_name": "Claude-3.6-Sonnet",
    "context_window": 256000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.045,
    "avg_latency_ms": 1500,
    "open_source": false,
    "capabilities": {
      "coding": 0.8,
      "math": 0.74,
      "reasoning": 0.9500000000000001,
      "support": 0.8,
      "writing": 0.95
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - anthropic flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.90)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.9
    }
  },
  {
    "id": "anthropic-claude-3-5-haiku",
    "provider": "anthropic",
    "display_name": "Claude-3.5-Haiku",
    "context_window": 384000,
    "cost_in_per_1k": 0.02,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 1800,
    "open_source": false,
    "capabilities": {
      "coding": 0.85,
      "math": 0.7799999999999999,
      "reasoning": 0.9800000000000001,
      "support": 0.8,
      "writing": 0.95
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - anthropic flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.95)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.95
    }
  },
  {
    "id": "google-gemini-3-ultra",
    "provider": "google",
    "display_name": "Gemini-3-Ultra",
    "context_window": 128000,
    "cost_in_per_1k": 0.03,
    "cost_out_per_1k": 0.09,
    "avg_latency_ms": 1200,
    "open_source": false,
    "capabilities": {
      "coding": 0.75,
      "math": 0.85,
      "reasoning": 0.9,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - google flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.85)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.85
    }
  },
  {
    "id": "google-gemini-2-5-pro-experimental",
    "provider": "google",
    "display_name": "Gemini-2.5-Pro-Experimental",
    "context_window": 256000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.045,
    "avg_latency_ms": 1500,
    "open_source": false,
    "capabilities": {
      "coding": 0.8,
      "math": 0.89,
      "reasoning": 0.93,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "closed",
      "reasoning",
      "math",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - google flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.90)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.9
    }
  },
  {
    "id": "google-palm-3",
    "provider": "google",
    "display_name": "PaLM-3",
    "context_window": 384000,
    "cost_in_per_1k": 0.02,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 1800,
    "open_source": false,
    "capabilities": {
      "coding": 0.85,
      "math": 0.9299999999999999,
      "reasoning": 0.9600000000000001,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "closed",
      "coding",
      "reasoning",
      "math",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - google flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.95)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.95
    }
  },
  {
    "id": "meta-llama-4-405b",
    "provider": "meta",
    "display_name": "Llama-4-405B",
    "context_window": 128000,
    "cost_in_per_1k": 0.03,
    "cost_out_per_1k": 0.09,
    "avg_latency_ms": 1200,
    "open_source": true,
    "capabilities": {
      "coding": 0.8,
      "math": 0.7,
      "reasoning": 0.8,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "open",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - meta flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.85)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.85
    }
  },
  {
    "id": "meta-llama-3-3-70b",
    "provider": "meta",
    "display_name": "Llama-3.3-70B",
    "context_window": 256000,
    "cost_in_per_1k": 0.015,
    "cost_out_per_1k": 0.045,
    "avg_latency_ms": 1500,
    "open_source": true,
    "capabilities": {
      "coding": 0.8500000000000001,
      "math": 0.74,
      "reasoning": 0.8300000000000001,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "open",
      "coding",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - meta flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.90)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.9
    }
  },
  {
    "id": "meta-llama-guard-3",
    "provider": "meta",
    "display_name": "Llama-Guard-3",
    "context_window": 384000,
    "cost_in_per_1k": 0.02,
    "cost_out_per_1k": 0.06,
    "avg_latency_ms": 1800,
    "open_source": true,
    "capabilities": {
      "coding": 0.9,
      "math": 0.7799999999999999,
      "reasoning": 0.8600000000000001,
      "support": 0.8,
      "writing": 0.85
    },
    "best_at": null,
    "tags": [
      "open",
      "coding",
      "reasoning",
      "safety",
      "parallel-ai-discovery"
    ],
    "notes": "Discovered via Parallel AI research - meta flagship model with advanced capabilities (Discovered: 2025-09-09, Confidence: 0.95)",
    "data_provenance": {
      "static_data": null,
      "scraped_data": null,
      "api_data": {
        "parallel_ai": "2025-09-09T10:02:46+05:30"
      },
      "last_consolidated": "2025-09-09T10:02:46+05:30",
      "data_quality": 0.95
    }
  }
]