version: "3.9"
services:
  api:
    build: { context: ., dockerfile: docker/Dockerfile.api }
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - CLASSIFIER_URL=http://classifier:5000
      - SQLITE_PATH=/app/data/router.db
      - MODEL_PROFILES_PATH=/app/configs/models.json
    ports: ["8081:8080"]
    depends_on: [classifier, ingestor]
    volumes: ["apidata:/app/data"]
  classifier:
    build: { context: ., dockerfile: docker/Dockerfile.classifier }
    ports: ["5001:5000"]
  ingestor:
    build: { context: ., dockerfile: docker/Dockerfile.ingestor }
    environment:
      - ROUTER_API=http://api:8080/ingest
      - SOURCES=open-llm-leaderboard,lmarena,artificialanalysis
      - AA_API_KEY=${AA_API_KEY}
      - HELM_GCS_BUCKET=crfm-helm-public
      - HELM_GCS_PREFIX=lite/benchmark_output/runs
      - HELM_GCS_SUITE=v1.0.0
      - HELM_GCS_LIMIT=50     
      - HELM_JSON_URLS=${HELM_JSON_URLS}
    ports: ["5100:5100"]
volumes: { apidata: {} }
